{
  "experiment": "pretrain",
  "task": "mlm",
  "dataset": "uniref50",
  "d_embed": 12,
  "d_model": 1024,
  "activation": "gelu",
  "slim": true,
  "epochs": 100,
  "n_layers": 16,
  "kernel_size": 5,
  "r": 128,
  "max_tokens": 40000,
  "max_batch_size": 800,
  "bucket_size": 1000,
  "opt_level": "O2",
  "lr": 1e-4,
  "warmup_steps": 16000,
  "train_steps": 8000
}