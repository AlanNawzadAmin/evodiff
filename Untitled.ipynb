{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14ba08c7-4c3b-4a5d-ad3e-43a154471fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from evodiff.utils import Tokenizer\n",
    "import pathlib\n",
    "from sequence_models.datasets import UniRefDataset\n",
    "from tqdm import tqdm\n",
    "from evodiff.plot import aa_reconstruction_parity_plot\n",
    "import pandas as pd\n",
    "from evodiff.pretrained import load_sequence_checkpoint\n",
    "from matplotlib import pyplot as plt\n",
    "import pkg_resources\n",
    "from evodiff.utils import Tokenizer\n",
    "\n",
    "\n",
    "home = str(pathlib.Path.home())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f4a2f1c1-86aa-4789-8b21-0c66fb4bfc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 8, 16, 32, 64, 128, 1, 2, 4, 8, 16, 32, 64, 128]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "model = ByteNetLMTime()\n",
    "collater = SimpleCollater(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2dcbe7e6-c8c5-4561-aae4-014334fe85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = UniRefDataset('data/uniref50/', 'train', structure=False, max_len=1024)\n",
    "data_valid = UniRefDataset('data/uniref50/', 'test', structure=False, max_len=1024)\n",
    "\n",
    "D =10\n",
    "seqs = [data_train[i] for i in range(D)]\n",
    "data = collater(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "485d86cc-4066-486c-a567-6ba6100697dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43683359"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "074c8b95-6cff-4d00-99fa-42558251c4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 543, 1024]) torch.Size([10, 1, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 543, 31])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data[0], torch.zeros(D).float(), torch.zeros(data[0].shape).float()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "94787716-a95c-4fcf-9d86-5c354badd603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SimpleCollater(object):\n",
    "    def __init__(self, tokenizer=Tokenizer()):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, sequences):\n",
    "        tokenized = [torch.tensor(self.tokenizer.tokenize(s)) for s in sequences]\n",
    "        tokenized = _pad(tokenized, self.tokenizer.pad_id)\n",
    "        masks = tokenized != self.tokenizer.pad_id\n",
    "        return tokenized.to(torch.long), masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8928e09-4b1b-4b12-9ef2-270324c0d0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evodiff",
   "language": "python",
   "name": "evodiff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
